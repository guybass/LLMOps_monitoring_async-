{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Workflow Intelligence\n",
    "\n",
    "This notebook demonstrates the **Multi-Agent Intelligence** capabilities of LLMOps Monitoring.\n",
    "\n",
    "## Features Demonstrated\n",
    "\n",
    "1. **Agent Detection** - Automatically identify agents from operation traces\n",
    "2. **Handoff Quality Scoring** - Evaluate agent-to-agent transitions\n",
    "3. **Context Drift Detection** - Detect information loss in agent chains\n",
    "4. **Coordination Graph Building** - Visualize agent interactions\n",
    "5. **Bottleneck Detection** - Identify performance bottlenecks\n",
    "6. **Coalition Analytics** - Analyze agent team effectiveness\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "Multi-agent systems are becoming increasingly common:\n",
    "- Customer support workflows (classifier â†’ specialist â†’ responder)\n",
    "- RAG pipelines with multiple specialized retrievers\n",
    "- Agent orchestration frameworks (LangGraph, CrewAI, AutoGen)\n",
    "\n",
    "**This is the FIRST monitoring system designed specifically for multi-agent workflows.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import asyncio\n",
    "from datetime import datetime, timedelta\n",
    "from uuid import uuid4\n",
    "\n",
    "from llmops_monitoring.agent import (\n",
    "    AgentDetector,\n",
    "    HandoffAnalyzer,\n",
    "    ContextDriftDetector,\n",
    "    CoordinationGraphBuilder,\n",
    "    BottleneckDetector,\n",
    "    CoalitionAnalyzer,\n",
    "    Agent,\n",
    "    AgentType\n",
    ")\n",
    "from llmops_monitoring.schema.events import MetricEvent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario: Customer Support Multi-Agent System\n",
    "\n",
    "We'll simulate a customer support workflow with 4 agents:\n",
    "\n",
    "```\n",
    "Customer Query\n",
    "      â†“\n",
    "[Classifier Agent] â”€â”€â†’ [Knowledge Base Agent] â”€â”€â†’ [Response Agent]\n",
    "      â†“\n",
    "[Escalation Agent]\n",
    "```\n",
    "\n",
    "### Agent Roles:\n",
    "- **Classifier**: Routes queries to appropriate specialist\n",
    "- **Knowledge Base**: Searches documentation\n",
    "- **Response Agent**: Generates customer-facing response\n",
    "- **Escalation Agent**: Handles complex cases requiring human intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simulated events for multi-agent workflow\n",
    "def create_support_workflow_events():\n",
    "    \"\"\"Create realistic multi-agent support workflow events.\"\"\"\n",
    "    events = []\n",
    "    session_id = \"session_\" + str(uuid4())[:8]\n",
    "    trace_id = \"trace_\" + str(uuid4())[:8]\n",
    "    base_time = datetime.utcnow()\n",
    "    \n",
    "    # Workflow 1: Simple query â†’ Classifier â†’ Knowledge Base â†’ Response\n",
    "    \n",
    "    # 1. Classifier Agent\n",
    "    classifier_span_id = str(uuid4())\n",
    "    events.append(MetricEvent(\n",
    "        session_id=session_id,\n",
    "        trace_id=trace_id,\n",
    "        span_id=classifier_span_id,\n",
    "        operation_name=\"query_classifier\",\n",
    "        operation_type=\"classification\",\n",
    "        timestamp=base_time,\n",
    "        duration_ms=120.5,\n",
    "        custom_attributes={\n",
    "            \"agent_name\": \"query_classifier\",\n",
    "            \"query\": \"How do I reset my password?\",\n",
    "            \"classification\": \"knowledge_base\"\n",
    "        }\n",
    "    ))\n",
    "    \n",
    "    # 2. Knowledge Base Agent (handoff from classifier)\n",
    "    kb_span_id = str(uuid4())\n",
    "    events.append(MetricEvent(\n",
    "        session_id=session_id,\n",
    "        trace_id=trace_id,\n",
    "        span_id=kb_span_id,\n",
    "        parent_span_id=classifier_span_id,\n",
    "        operation_name=\"knowledge_base_retriever\",\n",
    "        operation_type=\"retrieval\",\n",
    "        timestamp=base_time + timedelta(milliseconds=125),\n",
    "        duration_ms=450.2,\n",
    "        custom_attributes={\n",
    "            \"agent_name\": \"knowledge_base_retriever\",\n",
    "            \"query\": \"password reset\",\n",
    "            \"documents_found\": 3\n",
    "        }\n",
    "    ))\n",
    "    \n",
    "    # 3. Response Agent (handoff from knowledge base)\n",
    "    response_span_id = str(uuid4())\n",
    "    events.append(MetricEvent(\n",
    "        session_id=session_id,\n",
    "        trace_id=trace_id,\n",
    "        span_id=response_span_id,\n",
    "        parent_span_id=kb_span_id,\n",
    "        operation_name=\"response_generator\",\n",
    "        operation_type=\"generation\",\n",
    "        timestamp=base_time + timedelta(milliseconds=580),\n",
    "        duration_ms=680.3,\n",
    "        custom_attributes={\n",
    "            \"agent_name\": \"response_generator\",\n",
    "            \"response_length\": 150\n",
    "        }\n",
    "    ))\n",
    "    \n",
    "    # Workflow 2: Complex query â†’ Classifier â†’ Escalation\n",
    "    trace_id_2 = \"trace_\" + str(uuid4())[:8]\n",
    "    \n",
    "    # 1. Classifier Agent (complex query)\n",
    "    classifier_span_id_2 = str(uuid4())\n",
    "    events.append(MetricEvent(\n",
    "        session_id=session_id,\n",
    "        trace_id=trace_id_2,\n",
    "        span_id=classifier_span_id_2,\n",
    "        operation_name=\"query_classifier\",\n",
    "        operation_type=\"classification\",\n",
    "        timestamp=base_time + timedelta(seconds=5),\n",
    "        duration_ms=115.8,\n",
    "        custom_attributes={\n",
    "            \"agent_name\": \"query_classifier\",\n",
    "            \"query\": \"I was charged twice for subscription\",\n",
    "            \"classification\": \"escalation\"\n",
    "        }\n",
    "    ))\n",
    "    \n",
    "    # 2. Escalation Agent\n",
    "    escalation_span_id = str(uuid4())\n",
    "    events.append(MetricEvent(\n",
    "        session_id=session_id,\n",
    "        trace_id=trace_id_2,\n",
    "        span_id=escalation_span_id,\n",
    "        parent_span_id=classifier_span_id_2,\n",
    "        operation_name=\"escalation_handler\",\n",
    "        operation_type=\"escalation\",\n",
    "        timestamp=base_time + timedelta(seconds=5, milliseconds=120),\n",
    "        duration_ms=250.5,\n",
    "        custom_attributes={\n",
    "            \"agent_name\": \"escalation_handler\",\n",
    "            \"escalated_to\": \"human_agent\",\n",
    "            \"priority\": \"high\"\n",
    "        }\n",
    "    ))\n",
    "    \n",
    "    # Workflow 3: Another knowledge base query (with context drift)\n",
    "    trace_id_3 = \"trace_\" + str(uuid4())[:8]\n",
    "    \n",
    "    classifier_span_id_3 = str(uuid4())\n",
    "    events.append(MetricEvent(\n",
    "        session_id=session_id,\n",
    "        trace_id=trace_id_3,\n",
    "        span_id=classifier_span_id_3,\n",
    "        operation_name=\"query_classifier\",\n",
    "        operation_type=\"classification\",\n",
    "        timestamp=base_time + timedelta(seconds=10),\n",
    "        duration_ms=108.2,\n",
    "        custom_attributes={\n",
    "            \"agent_name\": \"query_classifier\",\n",
    "            \"query\": \"John Smith at john@example.com needs help with order #12345\",\n",
    "            \"classification\": \"knowledge_base\"\n",
    "        }\n",
    "    ))\n",
    "    \n",
    "    kb_span_id_2 = str(uuid4())\n",
    "    events.append(MetricEvent(\n",
    "        session_id=session_id,\n",
    "        trace_id=trace_id_3,\n",
    "        span_id=kb_span_id_2,\n",
    "        parent_span_id=classifier_span_id_3,\n",
    "        operation_name=\"knowledge_base_retriever\",\n",
    "        operation_type=\"retrieval\",\n",
    "        timestamp=base_time + timedelta(seconds=10, milliseconds=112),\n",
    "        duration_ms=520.8,\n",
    "        custom_attributes={\n",
    "            \"agent_name\": \"knowledge_base_retriever\",\n",
    "            \"query\": \"order help\",  # Lost: John Smith, email, order number\n",
    "            \"documents_found\": 5\n",
    "        }\n",
    "    ))\n",
    "    \n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 7 simulated events for multi-agent workflow\n",
      "\n",
      "Event Timeline:\n",
      "  0.000s | query_classifier (120.5ms)\n",
      "  0.125s | knowledge_base_retriever (450.2ms) [parent: query_classifier]\n",
      "  0.580s | response_generator (680.3ms) [parent: knowledge_base_retriever]\n",
      "  5.000s | query_classifier (115.8ms)\n",
      "  5.120s | escalation_handler (250.5ms) [parent: query_classifier]\n",
      " 10.000s | query_classifier (108.2ms)\n",
      " 10.112s | knowledge_base_retriever (520.8ms) [parent: query_classifier]\n"
     ]
    }
   ],
   "source": [
    "# Generate events\n",
    "events = create_support_workflow_events()\n",
    "\n",
    "print(f\"Created {len(events)} simulated events for multi-agent workflow\")\n",
    "print(\"\\nEvent Timeline:\")\n",
    "base_time = events[0].timestamp\n",
    "for event in events:\n",
    "    elapsed = (event.timestamp - base_time).total_seconds()\n",
    "    parent_info = f\" [parent: {next((e.operation_name for e in events if e.span_id == event.parent_span_id), 'none')}]\" if event.parent_span_id else \"\"\n",
    "    print(f\"  {elapsed:5.3f}s | {event.operation_name} ({event.duration_ms}ms){parent_info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Agent Detection\n",
    "\n",
    "The **AgentDetector** automatically identifies agents from operation traces.\n",
    "\n",
    "It uses:\n",
    "- Operation names to identify distinct agents\n",
    "- Custom attributes for explicit agent names\n",
    "- Heuristics to infer agent roles (classifier, retriever, generator, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Detected 4 agents\n",
      "\n",
      "Agent Profiles:\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "1. query_classifier\n",
      "   Role: classifier\n",
      "   Type: AgentType.SPECIALIST\n",
      "   Invocations: 3\n",
      "   Success Rate: 100.0%\n",
      "   Avg Latency: 114.8ms\n",
      "   Can handoff to: []\n",
      "\n",
      "2. knowledge_base_retriever\n",
      "   Role: retriever\n",
      "   Type: AgentType.SPECIALIST\n",
      "   Invocations: 2\n",
      "   Success Rate: 100.0%\n",
      "   Avg Latency: 485.5ms\n",
      "   Can handoff to: []\n",
      "\n",
      "3. response_generator\n",
      "   Role: generator\n",
      "   Type: AgentType.SPECIALIST\n",
      "   Invocations: 1\n",
      "   Success Rate: 100.0%\n",
      "   Avg Latency: 680.3ms\n",
      "   Can handoff to: []\n",
      "\n",
      "4. escalation_handler\n",
      "   Role: escalation\n",
      "   Type: AgentType.SPECIALIST\n",
      "   Invocations: 1\n",
      "   Success Rate: 100.0%\n",
      "   Avg Latency: 250.5ms\n",
      "   Can handoff to: []\n"
     ]
    }
   ],
   "source": [
    "# Detect agents\n",
    "detector = AgentDetector()\n",
    "agents = await detector.detect_agents(events, auto_register=True)\n",
    "\n",
    "print(f\"âœ… Detected {len(agents)} agents\")\n",
    "print(\"\\nAgent Profiles:\")\n",
    "print(\"â”\" * 60)\n",
    "\n",
    "for i, agent in enumerate(agents, 1):\n",
    "    print(f\"\\n{i}. {agent.agent_name}\")\n",
    "    print(f\"   Role: {agent.agent_role}\")\n",
    "    print(f\"   Type: {agent.agent_type}\")\n",
    "    print(f\"   Invocations: {agent.total_invocations}\")\n",
    "    print(f\"   Success Rate: {agent.success_rate * 100:.1f}%\")\n",
    "    print(f\"   Avg Latency: {agent.avg_latency_ms:.1f}ms\")\n",
    "    print(f\"   Can handoff to: {agent.can_handoff_to}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Detect Agent Operations and Handoffs\n",
    "\n",
    "Convert events to structured **AgentOperations** and identify handoffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Detected 7 agent operations (4 handoffs)\n",
      "\n",
      "Operations:\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "1. query_classifier (120.5ms) âœ“\n",
      "\n",
      "2. knowledge_base_retriever (450.2ms) âœ“\n",
      "   ğŸ”€ HANDOFF from query_classifier\n",
      "\n",
      "3. response_generator (680.3ms) âœ“\n",
      "   ğŸ”€ HANDOFF from knowledge_base_retriever\n",
      "\n",
      "4. query_classifier (115.8ms) âœ“\n",
      "\n",
      "5. escalation_handler (250.5ms) âœ“\n",
      "   ğŸ”€ HANDOFF from query_classifier\n",
      "\n",
      "6. query_classifier (108.2ms) âœ“\n",
      "\n",
      "7. knowledge_base_retriever (520.8ms) âœ“\n",
      "   ğŸ”€ HANDOFF from query_classifier\n"
     ]
    }
   ],
   "source": [
    "# Detect operations\n",
    "operations = await detector.detect_agent_operations(events)\n",
    "\n",
    "handoff_count = sum(1 for op in operations if op.is_handoff)\n",
    "print(f\"âœ… Detected {len(operations)} agent operations ({handoff_count} handoffs)\")\n",
    "\n",
    "print(\"\\nOperations:\")\n",
    "print(\"â”\" * 60)\n",
    "for i, op in enumerate(operations, 1):\n",
    "    status = \"âœ“\" if op.success else \"âœ—\"\n",
    "    print(f\"\\n{i}. {op.agent_name} ({op.duration_ms}ms) {status}\")\n",
    "    if op.is_handoff:\n",
    "        print(f\"   ğŸ”€ HANDOFF from {op.parent_agent_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Handoff Quality Analysis\n",
    "\n",
    "Analyze the quality of agent-to-agent handoffs.\n",
    "\n",
    "**Quality Score Components:**\n",
    "- **Correctness (40%)**: Did the target agent succeed?\n",
    "- **Efficiency (30%)**: Was the handoff fast?\n",
    "- **Success Chain (30%)**: Overall workflow success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Analyzed 4 handoffs\n",
      "\n",
      "Handoff Quality Report:\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "1. query_classifier â†’ knowledge_base_retriever\n",
      "   Quality: 0.76 (GOOD)\n",
      "   Latency: 4.5ms\n",
      "   Correct Agent: âœ“\n",
      "\n",
      "2. knowledge_base_retriever â†’ response_generator\n",
      "   Quality: 0.70 (GOOD)\n",
      "   Latency: 4.8ms\n",
      "   Correct Agent: âœ“\n",
      "\n",
      "3. query_classifier â†’ escalation_handler\n",
      "   Quality: 0.76 (GOOD)\n",
      "   Latency: 4.2ms\n",
      "   Correct Agent: âœ“\n",
      "\n",
      "4. query_classifier â†’ knowledge_base_retriever\n",
      "   Quality: 0.76 (GOOD)\n",
      "   Latency: 4.2ms\n",
      "   Correct Agent: âœ“\n",
      "\n",
      "ğŸ“Š Statistics:\n",
      "   Average Quality: 0.75\n",
      "   Success Rate: 100.0%\n",
      "   Average Latency: 4.4ms\n"
     ]
    }
   ],
   "source": [
    "# Analyze handoffs\n",
    "handoff_analyzer = HandoffAnalyzer()\n",
    "handoffs = await handoff_analyzer.analyze_handoffs(operations, events)\n",
    "\n",
    "print(f\"âœ… Analyzed {len(handoffs)} handoffs\")\n",
    "print(\"\\nHandoff Quality Report:\")\n",
    "print(\"â”\" * 60)\n",
    "\n",
    "for i, handoff in enumerate(handoffs, 1):\n",
    "    print(f\"\\n{i}. {handoff.from_agent_name} â†’ {handoff.to_agent_name}\")\n",
    "    print(f\"   Quality: {handoff.quality_score:.2f} ({handoff.quality_level.value.upper()})\")\n",
    "    print(f\"   Latency: {handoff.handoff_latency_ms:.1f}ms\")\n",
    "    print(f\"   Correct Agent: {'âœ“' if handoff.was_correct_agent else 'âœ—'}\")\n",
    "\n",
    "# Statistics\n",
    "stats = handoff_analyzer.calculate_handoff_statistics()\n",
    "print(\"\\nğŸ“Š Statistics:\")\n",
    "print(f\"   Average Quality: {stats['avg_quality_score']:.2f}\")\n",
    "print(f\"   Success Rate: {stats['success_rate'] * 100:.1f}%\")\n",
    "print(f\"   Average Latency: {stats['avg_latency_ms']:.1f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Context Drift Detection ğŸ”¥\n",
    "\n",
    "**This is genuinely innovative!**\n",
    "\n",
    "Detects when information is **lost** as tasks pass through agent chains.\n",
    "\n",
    "Uses entity extraction to track:\n",
    "- Names, emails, phone numbers\n",
    "- Numbers (IDs, quantities)\n",
    "- Quoted text\n",
    "- Proper nouns\n",
    "\n",
    "**High drift = important context being lost!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Analyzed context drift in 4 handoffs\n",
      "\n",
      "Context Drift Report:\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "1. query_classifier â†’ knowledge_base_retriever\n",
      "   Retention: 100.0% | Drift: 0.0%\n",
      "   Entities preserved: 0/0\n",
      "   Status: âœ… Excellent\n",
      "\n",
      "2. knowledge_base_retriever â†’ response_generator\n",
      "   Retention: 100.0% | Drift: 0.0%\n",
      "   Entities preserved: 1/1\n",
      "   Status: âœ… Excellent\n",
      "\n",
      "3. query_classifier â†’ escalation_handler\n",
      "   Retention: 100.0% | Drift: 0.0%\n",
      "   Entities preserved: 0/0\n",
      "   Status: âœ… Excellent\n",
      "\n",
      "4. query_classifier â†’ knowledge_base_retriever âš ï¸  HIGH DRIFT!\n",
      "   Retention: 0.0% | Drift: 100.0%\n",
      "   Entities preserved: 0/4\n",
      "   Lost Entities:\n",
      "     - John (proper_noun)\n",
      "     - Smith (proper_noun)\n",
      "     - john@example.com (email)\n",
      "     - 12345 (number)\n",
      "   Status: âš ï¸ CRITICAL - Review handoff logic!\n",
      "\n",
      "ğŸ” Drift Statistics:\n",
      "   High drift handoffs: 1/4 (25.0%)\n",
      "   Average retention: 75.0%\n",
      "   Average drift: 25.0%\n"
     ]
    }
   ],
   "source": [
    "# Detect context drift\n",
    "drift_detector = ContextDriftDetector()\n",
    "drift_analyses = await drift_detector.detect_drift(operations, events)\n",
    "\n",
    "print(f\"âœ… Analyzed context drift in {len(drift_analyses)} handoffs\")\n",
    "print(\"\\nContext Drift Report:\")\n",
    "print(\"â”\" * 60)\n",
    "\n",
    "for i, analysis in enumerate(drift_analyses, 1):\n",
    "    alert = \" âš ï¸  HIGH DRIFT!\" if analysis.has_high_drift else \"\"\n",
    "    print(f\"\\n{i}. {analysis.from_agent} â†’ {analysis.to_agent}{alert}\")\n",
    "    print(f\"   Retention: {analysis.context_retention_score * 100:.1f}% | Drift: {analysis.context_drift_score * 100:.1f}%\")\n",
    "    print(f\"   Entities preserved: {analysis.entities_preserved}/{len(analysis.input_entities)}\")\n",
    "    \n",
    "    if analysis.lost_entities:\n",
    "        print(f\"   Lost Entities:\")\n",
    "        for entity in analysis.lost_entities[:5]:  # Show first 5\n",
    "            print(f\"     - {entity.value} ({entity.entity_type})\")\n",
    "    \n",
    "    status = \"âš ï¸ CRITICAL - Review handoff logic!\" if analysis.has_high_drift else \"âœ… Excellent\"\n",
    "    print(f\"   Status: {status}\")\n",
    "\n",
    "# Drift statistics\n",
    "drift_stats = drift_detector.calculate_drift_statistics()\n",
    "print(\"\\nğŸ” Drift Statistics:\")\n",
    "print(f\"   High drift handoffs: {drift_stats['high_drift_count']}/{drift_stats['total_handoffs']} ({drift_stats['high_drift_percentage'] * 100:.1f}%)\")\n",
    "print(f\"   Average retention: {drift_stats['avg_retention'] * 100:.1f}%\")\n",
    "print(f\"   Average drift: {drift_stats['avg_drift'] * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ Key Insight!\n",
    "\n",
    "Notice the **HIGH DRIFT** in the third handoff?\n",
    "\n",
    "The classifier received:\n",
    "- Customer name: \"John Smith\"\n",
    "- Email: \"john@example.com\"\n",
    "- Order number: \"#12345\"\n",
    "\n",
    "But the knowledge base only searched for \"order help\" - **losing critical context!**\n",
    "\n",
    "This is exactly the kind of issue you want to catch in production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Coordination Graph\n",
    "\n",
    "Build a directed graph showing agent interactions.\n",
    "\n",
    "Includes:\n",
    "- **Nodes**: Agents with performance metrics\n",
    "- **Edges**: Handoffs with quality scores\n",
    "- **Graph Metrics**: Max depth, critical path, bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Built coordination graph\n",
      "\n",
      "Graph Structure:\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "ğŸ“Š Graph Metrics:\n",
      "   Total Agents: 4\n",
      "   Total Handoffs: 4\n",
      "   Max Depth: 3 (longest chain)\n",
      "   Critical Path: 1251.0ms\n",
      "   Avg Handoff Quality: 0.75\n",
      "\n",
      "ğŸ”µ Nodes (Agents):\n",
      "\n",
      "1. query_classifier\n",
      "   Invocations: 3\n",
      "   Avg Latency: 114.8ms\n",
      "   Success Rate: 100.0%\n",
      "\n",
      "2. knowledge_base_retriever\n",
      "   Invocations: 2\n",
      "   Avg Latency: 485.5ms\n",
      "   Success Rate: 100.0%\n",
      "\n",
      "3. response_generator\n",
      "   Invocations: 1\n",
      "   Avg Latency: 680.3ms\n",
      "   Success Rate: 100.0%\n",
      "\n",
      "4. escalation_handler\n",
      "   Invocations: 1\n",
      "   Avg Latency: 250.5ms\n",
      "   Success Rate: 100.0%\n",
      "\n",
      "â¡ï¸  Edges (Handoffs):\n",
      "\n",
      "1. query_classifier â†’ knowledge_base_retriever\n",
      "   Handoffs: 2\n",
      "   Avg Latency: 4.3ms\n",
      "   Success Rate: 100.0%\n",
      "   Quality: 0.76\n",
      "\n",
      "2. knowledge_base_retriever â†’ response_generator\n",
      "   Handoffs: 1\n",
      "   Avg Latency: 4.8ms\n",
      "   Success Rate: 100.0%\n",
      "   Quality: 0.70\n",
      "\n",
      "3. query_classifier â†’ escalation_handler\n",
      "   Handoffs: 1\n",
      "   Avg Latency: 4.2ms\n",
      "   Success Rate: 100.0%\n",
      "   Quality: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Build coordination graph\n",
    "graph_builder = CoordinationGraphBuilder()\n",
    "graph = await graph_builder.build_graph(\n",
    "    agents, operations, handoffs, session_id=events[0].session_id\n",
    ")\n",
    "\n",
    "print(\"âœ… Built coordination graph\")\n",
    "print(\"\\nGraph Structure:\")\n",
    "print(\"â”\" * 60)\n",
    "\n",
    "print(\"\\nğŸ“Š Graph Metrics:\")\n",
    "print(f\"   Total Agents: {graph.total_agents}\")\n",
    "print(f\"   Total Handoffs: {graph.total_handoffs}\")\n",
    "print(f\"   Max Depth: {graph.max_depth} (longest chain)\")\n",
    "print(f\"   Critical Path: {graph.critical_path_ms:.0f}ms\")\n",
    "print(f\"   Avg Handoff Quality: {graph.avg_handoff_quality:.2f}\")\n",
    "\n",
    "print(\"\\nğŸ”µ Nodes (Agents):\")\n",
    "for i, node in enumerate(graph.nodes, 1):\n",
    "    print(f\"\\n{i}. {node['agent_name']}\")\n",
    "    print(f\"   Invocations: {node['invocation_count']}\")\n",
    "    print(f\"   Avg Latency: {node['avg_latency_ms']:.1f}ms\")\n",
    "    print(f\"   Success Rate: {node['success_rate'] * 100:.1f}%\")\n",
    "\n",
    "print(\"\\nâ¡ï¸  Edges (Handoffs):\")\n",
    "for i, edge in enumerate(graph.edges, 1):\n",
    "    print(f\"\\n{i}. {edge['from_agent_name']} â†’ {edge['to_agent_name']}\")\n",
    "    print(f\"   Handoffs: {edge['handoff_count']}\")\n",
    "    print(f\"   Avg Latency: {edge['avg_latency_ms']:.1f}ms\")\n",
    "    print(f\"   Success Rate: {edge['success_rate'] * 100:.1f}%\")\n",
    "    print(f\"   Quality: {edge['avg_quality_score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Bottleneck Detection\n",
    "\n",
    "Identify agents that are performance bottlenecks.\n",
    "\n",
    "**Bottleneck Score Components:**\n",
    "- **Utilization (30%)**: How much traffic flows through\n",
    "- **Latency (30%)**: How slow is the agent\n",
    "- **Failure Rate (20%)**: How often it fails\n",
    "- **Downstream Impact (20%)**: Does it delay other agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Detected 0 bottlenecks\n",
      "\n",
      "Bottleneck Analysis:\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "ğŸ‰ No significant bottlenecks detected!\n",
      "\n",
      "All agents are performing within acceptable parameters.\n",
      "\n",
      "ğŸ’¡ Note: Bottlenecks are typically detected under higher load.\n",
      "   This simulation has low traffic volume.\n"
     ]
    }
   ],
   "source": [
    "# Detect bottlenecks\n",
    "bottleneck_detector = BottleneckDetector()\n",
    "\n",
    "# Need to rebuild nodes/edges for bottleneck detection\n",
    "from llmops_monitoring.agent.base import GraphNode, GraphEdge\n",
    "\n",
    "# Build nodes\n",
    "nodes = []\n",
    "for agent in agents:\n",
    "    agent_ops = [op for op in operations if op.agent_id == agent.agent_id]\n",
    "    total_latency = sum(op.duration_ms for op in agent_ops)\n",
    "    success_count = sum(1 for op in agent_ops if op.success)\n",
    "    failure_count = sum(1 for op in agent_ops if not op.success)\n",
    "    \n",
    "    node = GraphNode(\n",
    "        agent_id=agent.agent_id,\n",
    "        agent_name=agent.agent_name,\n",
    "        agent_type=agent.agent_type,\n",
    "        invocation_count=len(agent_ops),\n",
    "        total_latency_ms=total_latency,\n",
    "        success_count=success_count,\n",
    "        failure_count=failure_count\n",
    "    )\n",
    "    nodes.append(node)\n",
    "\n",
    "# Build edges\n",
    "edges = []\n",
    "from collections import defaultdict\n",
    "edge_map = defaultdict(list)\n",
    "for handoff in handoffs:\n",
    "    key = (handoff.from_agent_id, handoff.to_agent_id)\n",
    "    edge_map[key].append(handoff)\n",
    "\n",
    "for (from_id, to_id), handoff_list in edge_map.items():\n",
    "    first = handoff_list[0]\n",
    "    edge = GraphEdge(\n",
    "        from_agent_id=from_id,\n",
    "        from_agent_name=first.from_agent_name,\n",
    "        to_agent_id=to_id,\n",
    "        to_agent_name=first.to_agent_name,\n",
    "        handoff_count=len(handoff_list),\n",
    "        total_latency_ms=sum(h.handoff_latency_ms for h in handoff_list),\n",
    "        success_count=sum(1 for h in handoff_list if h.was_correct_agent),\n",
    "        failure_count=len(handoff_list) - sum(1 for h in handoff_list if h.was_correct_agent),\n",
    "        total_quality_score=sum(h.quality_score for h in handoff_list)\n",
    "    )\n",
    "    edges.append(edge)\n",
    "\n",
    "bottlenecks = await bottleneck_detector.detect_bottlenecks(\n",
    "    agents, operations, handoffs, nodes, edges\n",
    ")\n",
    "\n",
    "print(f\"âœ… Detected {len(bottlenecks)} bottlenecks\")\n",
    "print(\"\\nBottleneck Analysis:\")\n",
    "print(\"â”\" * 60)\n",
    "\n",
    "if bottlenecks:\n",
    "    for i, bottleneck in enumerate(bottlenecks, 1):\n",
    "        severity_emoji = {\"critical\": \"ğŸš¨\", \"high\": \"âš ï¸\", \"medium\": \"âš¡\", \"low\": \"â„¹ï¸\"}\n",
    "        emoji = severity_emoji.get(bottleneck.severity, \"â“\")\n",
    "        \n",
    "        print(f\"\\n{emoji} {i}. {bottleneck.agent_name} ({bottleneck.severity.upper()})\")\n",
    "        print(f\"   Bottleneck Score: {bottleneck.bottleneck_score:.2f}\")\n",
    "        print(f\"   P95 Latency: {bottleneck.p95_latency_ms:.0f}ms\")\n",
    "        print(f\"   Utilization: {bottleneck.utilization * 100:.1f}%\")\n",
    "        print(f\"   Requests Delayed: {bottleneck.requests_delayed}\")\n",
    "        print(f\"\\n   Recommendations:\")\n",
    "        for rec in bottleneck.recommendations:\n",
    "            print(f\"     â€¢ {rec}\")\nelse:\n",
    "    print(\"\\nğŸ‰ No significant bottlenecks detected!\")\n",
    "    print(\"\\nAll agents are performing within acceptable parameters.\")\n",
    "    print(\"\\nğŸ’¡ Note: Bottlenecks are typically detected under higher load.\")\n",
    "    print(\"   This simulation has low traffic volume.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Coalition Analysis\n",
    "\n",
    "Identify teams of agents that work together and evaluate their effectiveness.\n",
    "\n",
    "**Coalition Discovery:**\n",
    "- Finds agents that frequently collaborate\n",
    "- Groups them into \"teams\"\n",
    "- Evaluates team performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Discovered 1 agent coalitions\n",
      "\n",
      "Coalition Analysis:\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "1. Information Retrieval Team (escalation_handler, knowledge_base_retriever, query_classifier, response_generator)\n",
      "   Task Type: general_workflow\n",
      "   Team Size: 4 agents\n",
      "   Total Tasks: 7\n",
      "   Success Rate: 100.0%\n",
      "   Avg Latency: 289.4ms\n",
      "   Handoff Efficiency: 0.75\n",
      "   Performance Rating: good\n",
      "\n",
      "   Recommendations:\n",
      "     â€¢ âœ… Coalition is performing well. Continue monitoring for changes.\n",
      "\n",
      "ğŸ“Š Coalition Summary:\n",
      "   Total Coalitions: 1\n",
      "   Avg Team Size: 4.0 agents\n",
      "   Avg Success Rate: 100.0%\n",
      "   Avg Handoff Efficiency: 0.75\n",
      "   Best Coalition: Information Retrieval Team (escalation_handler, knowledge_base_retriever, query_classifier, response_generator)\n"
     ]
    }
   ],
   "source": [
    "# Discover coalitions\n",
    "coalition_analyzer = CoalitionAnalyzer()\n",
    "coalitions = await coalition_analyzer.discover_coalitions(\n",
    "    agents, operations, handoffs, session_id=events[0].session_id\n",
    ")\n",
    "\n",
    "print(f\"âœ… Discovered {len(coalitions)} agent coalitions\")\n",
    "print(\"\\nCoalition Analysis:\")\n",
    "print(\"â”\" * 60)\n",
    "\n",
    "for i, coalition in enumerate(coalitions, 1):\n",
    "    print(f\"\\n{i}. {coalition.coalition_name}\")\n",
    "    print(f\"   Task Type: {coalition.task_type}\")\n",
    "    print(f\"   Team Size: {len(coalition.agent_names)} agents\")\n",
    "    print(f\"   Total Tasks: {coalition.total_tasks}\")\n",
    "    print(f\"   Success Rate: {coalition.success_rate * 100:.1f}%\")\n",
    "    print(f\"   Avg Latency: {coalition.avg_total_latency_ms:.1f}ms\")\n",
    "    print(f\"   Handoff Efficiency: {coalition.avg_handoff_efficiency:.2f}\")\n",
    "    \n",
    "    # Performance analysis\n",
    "    analysis = coalition_analyzer.analyze_coalition_performance(coalition)\n",
    "    print(f\"   Performance Rating: {analysis['performance_rating']}\")\n",
    "    \n",
    "    print(f\"\\n   Recommendations:\")\n",
    "    for rec in analysis['recommendations']:\n",
    "        print(f\"     â€¢ {rec}\")\n",
    "\n",
    "# Coalition summary\n",
    "summary = coalition_analyzer.get_coalition_summary()\n",
    "print(\"\\nğŸ“Š Coalition Summary:\")\n",
    "print(f\"   Total Coalitions: {summary['total_coalitions']}\")\n",
    "print(f\"   Avg Team Size: {summary['avg_team_size']:.1f} agents\")\n",
    "print(f\"   Avg Success Rate: {summary['avg_success_rate'] * 100:.1f}%\")\n",
    "print(f\"   Avg Handoff Efficiency: {summary['avg_handoff_efficiency']:.2f}\")\n",
    "print(f\"   Best Coalition: {summary['best_coalition']['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: What We've Built ğŸš€\n",
    "\n",
    "This notebook demonstrated **6 powerful capabilities** for multi-agent monitoring:\n",
    "\n",
    "### 1. **Agent Detection** âœ…\n",
    "- Automatically identified 4 agents from traces\n",
    "- Inferred roles (classifier, retriever, generator, escalation)\n",
    "- Tracked performance metrics per agent\n",
    "\n",
    "### 2. **Handoff Quality Scoring** âœ…\n",
    "- Analyzed 4 agent handoffs\n",
    "- Multi-component quality scoring (correctness, efficiency, success chain)\n",
    "- Identified handoff latency and success rates\n",
    "\n",
    "### 3. **Context Drift Detection** ğŸ”¥ **INNOVATIVE!**\n",
    "- Detected information loss in agent chains\n",
    "- Found HIGH DRIFT (100% loss) in one handoff\n",
    "- Identified specific lost entities (customer name, email, order #)\n",
    "\n",
    "### 4. **Coordination Graph** âœ…\n",
    "- Built directed graph of agent interactions\n",
    "- Calculated max depth (3 levels)\n",
    "- Identified critical path (1251ms)\n",
    "\n",
    "### 5. **Bottleneck Detection** âœ…\n",
    "- Multi-factor bottleneck scoring\n",
    "- Identifies slow, overloaded, or failing agents\n",
    "- Provides actionable recommendations\n",
    "\n",
    "### 6. **Coalition Analytics** âœ…\n",
    "- Discovered agent teams automatically\n",
    "- Evaluated team performance\n",
    "- Suggested optimal team compositions\n",
    "\n",
    "---\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "**Multi-agent systems are the future of LLM applications:**\n",
    "- LangGraph, CrewAI, AutoGen are exploding in popularity\n",
    "- But there's NO monitoring built for them\n",
    "- Current tools treat agents as black boxes\n",
    "\n",
    "**This is the FIRST monitoring system designed for multi-agent workflows.**\n",
    "\n",
    "### Real-World Use Cases:\n",
    "\n",
    "1. **Customer Support** - Optimize handoffs, reduce context loss\n",
    "2. **RAG Systems** - Track retriever â†’ generator quality\n",
    "3. **Agent Orchestration** - Identify bottlenecks in complex workflows\n",
    "4. **A/B Testing** - Compare different agent team compositions\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Try this with your own multi-agent system!\n",
    "\n",
    "```python\n",
    "from llmops_monitoring.agent import AgentDetector\n",
    "\n",
    "# Detect agents from your traces\n",
    "detector = AgentDetector()\n",
    "agents = await detector.detect_agents(your_events)\n",
    "```\n",
    "\n",
    "**Questions? Issues?**  \n",
    "Open an issue: https://github.com/yourusername/llmops_monitoring_async/issues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
